# Default configuration for Multimodal MCTS QA system

# Models configuration
models:
  llava:
    model_name: "llava-hf/llava-1.5-7b-hf"
    device: "cuda"  # Set to "cpu" if no GPU is available
    max_new_tokens: 512
    generate_kwargs:
      temperature: 0.7
      do_sample: true
      top_p: 0.9
  
  llama:
    model_name: "meta-llama/Llama-2-7b-chat-hf"
    device: "cuda"  # Set to "cpu" if no GPU is available
    max_new_tokens: 512
    temperature: 0.7
    system_prompt: null  # Use default if null

# OCR configuration
ocr:
  tesseract_cmd: null  # Path to Tesseract executable (if not in PATH)
  lang: "eng"
  config: "--psm 6"

# MCTS configuration
mcts:
  time_limit: 30.0
  max_iterations: 100
  exploration_weight: 1.0

# Dataset configuration
dataset:
  data_dir: "data/scienceqa"
  image_dir: null  # Use default if null
  split: "val"
  load_images: true

# Evaluation configuration
evaluation:
  num_examples: 10
  output_dir: "results"
  save_visualizations: true

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  save_to_file: true
  log_file: "logs/multimodal_mcts_qa.log" 